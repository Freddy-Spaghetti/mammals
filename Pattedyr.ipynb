{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the dataset and getting an overview"
      ],
      "metadata": {
        "id": "8VDGMOYYd0-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMHMvM3MZfJL",
        "outputId": "ac2907c2-c98e-4aab-8978-8fd6fdf98065"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pywaffle"
      ],
      "metadata": {
        "id": "awi8T1HR6qgk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0818d4c-d6e5-44c7-a498-a63ae8a54136"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pywaffle\n",
            "  Downloading pywaffle-1.1.0-py2.py3-none-any.whl (30 kB)\n",
            "Collecting fontawesomefree (from pywaffle)\n",
            "  Downloading fontawesomefree-6.5.0-py3-none-any.whl (35.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.5/35.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from pywaffle) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pywaffle) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pywaffle) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pywaffle) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pywaffle) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pywaffle) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pywaffle) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pywaffle) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pywaffle) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pywaffle) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->pywaffle) (1.16.0)\n",
            "Installing collected packages: fontawesomefree, pywaffle\n",
            "Successfully installed fontawesomefree-6.5.0 pywaffle-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install geopandas"
      ],
      "metadata": {
        "id": "wNjkq0t3-SKB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f955a68-62f1-435e-c9b2-a2086b0c5f37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: fiona>=1.8.19 in /usr/local/lib/python3.10/dist-packages (from geopandas) (1.9.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from geopandas) (23.2)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (1.5.3)\n",
            "Requirement already satisfied: pyproj>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from geopandas) (3.6.1)\n",
            "Requirement already satisfied: shapely>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from geopandas) (2.0.2)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (23.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (2023.7.22)\n",
            "Requirement already satisfied: click~=8.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (8.1.7)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (1.1.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (0.7.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (1.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (67.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->geopandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->geopandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->geopandas) (1.23.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install folium"
      ],
      "metadata": {
        "id": "LrLDSkyb-UZ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaa12371-5dfc-4dcb-dca9-4bc2485b93f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: folium in /usr/local/lib/python3.10/dist-packages (0.14.0)\n",
            "Requirement already satisfied: branca>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from folium) (0.7.0)\n",
            "Requirement already satisfied: jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from folium) (3.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from folium) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from folium) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.9->folium) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->folium) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->folium) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->folium) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->folium) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moFvHj0SGeGx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "b3a5e8fd-3e70-44c4-c742-c9ba319dc75d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-9b19ed34890b>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmammal_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"/content/drive/MyDrive/Python/arter_pattedyr.xlsx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1650\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1652\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1653\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1523\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1525\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1526\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Python/arter_pattedyr.xlsx'"
          ]
        }
      ],
      "source": [
        "import pandas as pd #for working with dataframes\n",
        "import matplotlib.pyplot as plt #for general visualizations\n",
        "from pywaffle import Waffle #for waffle charts\n",
        "import geopandas as gpd #for working with geographical data\n",
        "import folium as fm #for visualizing with maps\n",
        "from IPython.display import display\n",
        "\n",
        "mammal_data = pd.read_excel(r\"/content/drive/MyDrive/Python/arter_pattedyr.xlsx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset we have chosen is from arter.dk, which is...\n",
        "\n",
        "First of all, we describe som basic details about the dataset."
      ],
      "metadata": {
        "id": "DR0CG-cDpZio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The dataset contains {mammal_data.shape[0]} rows and {mammal_data.shape[1]} columns. Thereby there are {mammal_data.size} cells in the dataset.\") #describing the numbers of rows, columns, and cells in the dataset"
      ],
      "metadata": {
        "id": "iaFc9dgaWjVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The columns contain these types of data:\\n\")\n",
        "mammal_data.info()"
      ],
      "metadata": {
        "id": "THBSU9cHXJUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we make sure that the license permits us to use the data."
      ],
      "metadata": {
        "id": "owS07X7bptcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(pd.isnull(mammal_data['License']).sum()) #confirming that there are no missing values in the license column\n",
        "print(mammal_data.groupby('License')['License'].count()) #confirming that there are no differing license type for any data points"
      ],
      "metadata": {
        "id": "y6PpcVWxoI6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The CC by 4.0 means that we can use the data..."
      ],
      "metadata": {
        "id": "9XdUDAIddsLM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploring and cleaning the dataset\n",
        "\n",
        "Next, we remove all columns, where more data points are missing than not, as we only wish to use columns where we can use close to all rows for analysis."
      ],
      "metadata": {
        "id": "_njzwQf2qcQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mammal_data.dropna(axis=1, thresh = 0.5 * len(mammal_data), inplace = True) #removing columns with missing values in more than half the observations\n",
        "mammal_data.info() #displaying the remaining columns"
      ],
      "metadata": {
        "id": "qQlnnxagX8G8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the next step, we found out that two of the columns contain personal information by having the name of the observer of the animal and the one adding it to the database. We believe that it is unethical to display PIIs unnessecarily, and therefore we drop those columns before displaying the content of the dataframe."
      ],
      "metadata": {
        "id": "3C6I4GmErzQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#removing the columns with names of persons\n",
        "mammal_data.drop(['Observatør(er)', #not relevant. Can perhaps be transformed into numerical values and be used to predict subregion (location)\n",
        "                  'Indtaster'], #not relevant\n",
        "                  axis=1, inplace = True)"
      ],
      "metadata": {
        "id": "A106ZvG7sWNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are able to get a better overview of what the remaining columns actually contain."
      ],
      "metadata": {
        "id": "UBB1_YJTrF9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None) #displaying all columns instead of just some\n",
        "mammal_data.head(10) #displaying the 10 first rows"
      ],
      "metadata": {
        "id": "t55Birx8YUVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upon inspection, we remove some of the columns. The reason is stated in a comment."
      ],
      "metadata": {
        "id": "Rq8cRrk9rSs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mammal_data.drop(['Systemoprindelse', #not relevant\n",
        "                  'Observationstidspunkt', #too specific to be useful\n",
        "                  'Indsamlet',#not relevant\n",
        "                  'Fundtype', #not relevant\n",
        "                  'Valideret', #not relevant\n",
        "                  'License', #we already confirmed that all data points has the same license and that we can use the data\n",
        "                  'Link', #not relevant\n",
        "                  'Arter taxon ID', #not relevant\n",
        "                  'Sløret', #not relevant\n",
        "                  'Klasse latinsk navn', #redundant as the chosen data only contains mammals\n",
        "                  'Klasse dansk navn', #redundant as the chosen data only contains mammals\n",
        "                  'Accepteret dansk art', #not relevant\n",
        "                  'Artsgruppe'], #redundant as the chosen data only contains mammals\n",
        "                  axis=1, inplace = True)"
      ],
      "metadata": {
        "id": "lRI-A-e0Z1oB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's have a look at the remaining data."
      ],
      "metadata": {
        "id": "dn_Nsg75tDw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mammal_data.head(10) #displaying the 10 first rows"
      ],
      "metadata": {
        "id": "i5Sn1HJJddDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we would like to convert the observation date to year, as we only wish to visualize and categorize per year."
      ],
      "metadata": {
        "id": "4z8-YX3Bccx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mammal_data[\"Observationsdato\"] = mammal_data[\"Observationsdato\"].str.split(\"-\").str[1] #only keeping the characters after the hyphen in the date"
      ],
      "metadata": {
        "id": "IkWl-WjOUFWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to inspect the different types of data in the 'Taxonrang' column, as there seems to be some rare values. Ideally 'Taxonrang' should only include 'Art', meaning species."
      ],
      "metadata": {
        "id": "FcAhWiZztXYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mammal_data.groupby('Taxonrang')['Taxonrang'].count()"
      ],
      "metadata": {
        "id": "3DDcIJ5wgdRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we inspect rows containing the three rarest values to see why they differ.\n"
      ],
      "metadata": {
        "id": "mc3babiatu93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mammal_data.loc[mammal_data['Taxonrang'] == 'SLÆGT']"
      ],
      "metadata": {
        "id": "znosG4flhQ3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mammal_data.loc[mammal_data['Taxonrang'] == 'SUPERART']"
      ],
      "metadata": {
        "id": "S1ITJaJ5hhMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For 'SUPERART' and 'SLÆGT', it is related to two types of bats being near identical in looks, why they were formerly considered the same species. Therefore the observer has been in doubt about the exact species. For convenience, we will convert all these into 'Pipistrelflagermus' in the column 'Taxon dansk navn', as it would not make sense to have them separated when visualizing the data.\n",
        "\n",
        "\n",
        "\n",
        "[About 'superarter'](https://om.arter.dk/vidensbase/hjaelp-til-arters-webside/artsbogen/der-findes-arter-men-ogsa-slaegter-ordener-og-taxa/)\n",
        "\n",
        "[About the difference between Pipistrellus and Pygmaeus](https://pattedyratlas.lex.dk/Pipistrelflagermus)\n"
      ],
      "metadata": {
        "id": "WsCxQ97-uWfw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mammal_data.loc[[5442, 1439, 4408],'Taxon dansk navn'] = \"Pipistrelflagermus\" #changing the value manually based on the index"
      ],
      "metadata": {
        "id": "fVYwjj82m1tT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For 'UNDERART', 'Muflon' does not match another species directly, as it is just a more specific indicator, therefore we will leave it be."
      ],
      "metadata": {
        "id": "1jSZM5g-wY4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mammal_data.loc[mammal_data['Taxonrang'] == 'UNDERART']"
      ],
      "metadata": {
        "id": "E0y9tDRMhhbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is in the same family as the 'Europæisk bison', but it would not be correct to convert it to the same."
      ],
      "metadata": {
        "id": "Habl22v7xVT-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mammal_data.loc[mammal_data['Familie latinsk navn'] == 'Bovidae']"
      ],
      "metadata": {
        "id": "yu9Wz-fOwwE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we saw in the beginning, the Danish order name has many more missing values than the Lation order name, why we will focus on filling in that column for later use. In 245 cases, the observer has just put in the taxonimical order, likely if they have not been aware of the exact species."
      ],
      "metadata": {
        "id": "aOR6vZeUpDJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_nan_orden = mammal_data[mammal_data[\"Orden latinsk navn\"].isna()]\n",
        "df_nan_orden.groupby(\"Taxon dansk navn\")[\"Taxon dansk navn\"].count()"
      ],
      "metadata": {
        "id": "EXGXtF_MpMWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now know that in 244 cases, it has been an unspecified bat, and in 1 case it has been an unspecified whale. As the order is mentioned in the taxon coloumn, it is not also in the order column, but we would like to have it this way."
      ],
      "metadata": {
        "id": "V8pnXlruqn1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "row_selector_bat = mammal_data[\"Taxon dansk navn\"] == \"Flagermus\"\n",
        "mammal_data.loc[row_selector_bat, \"Orden latinsk navn\"] = \"Chiroptera\"\n",
        "\n",
        "row_selector_whale = mammal_data[\"Taxon dansk navn\"] == \"Hvaler\"\n",
        "mammal_data.loc[row_selector_whale, \"Orden latinsk navn\"] = \"Cetacea\"\n",
        "\n",
        "mammal_data[\"Taxon dansk navn\"].isnull().values.any() #checks for any missing values in the column"
      ],
      "metadata": {
        "id": "86pojBFurg1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now there are no more missing values in the latin order column."
      ],
      "metadata": {
        "id": "sSyXxpgE2fF8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We could do the same check for the rows with the value 'Familie', meaning family, in 'Taxonrang', but we will use the order rather than the family for analysis, and therefore it is redundant to fill the missing values in that column as well."
      ],
      "metadata": {
        "id": "VpymeO_Tv4C9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After our initial cleaning, we will now use groupby and descriptive statistics to get to know our values better."
      ],
      "metadata": {
        "id": "UwDAtvbWfQXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mammal_data.groupby(\"Observationsdato\")[\"Observationsdato\"].count() #counting observations per year"
      ],
      "metadata": {
        "id": "vhGC8DuwV2CU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can see that nearly all observations of animals are between 2020 and 2023. This is important to consider, as we wish to do some graphs over time, and this is not a very long useful timespan.\n",
        "\n",
        "\n",
        "\n",
        "As we do not memorize the latin family names by heart, we want to display the most common animal for each family to help get an overview."
      ],
      "metadata": {
        "id": "YV7bysKri-D4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mammal_data.groupby(\"Orden latinsk navn\")[\"Taxon dansk navn\"].agg(pd.Series.mode)"
      ],
      "metadata": {
        "id": "jZByemnG2ueI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we wish to see some basic descriptive statistics on the 'Orden latinsk navn' column"
      ],
      "metadata": {
        "id": "6tkYwT3kJ58Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mammal_data[\"Orden latinsk navn\"].describe()"
      ],
      "metadata": {
        "id": "W_Eje1eaJvNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To see more detail in terms of the frequency of all unique values, we check the amount of animals in the different orders."
      ],
      "metadata": {
        "id": "BP-YKTb54P9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mammal_data['Orden latinsk navn'].value_counts()"
      ],
      "metadata": {
        "id": "ZNvciNgMvla2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visialize the proportion of each animal order we have used a waffle chart, which we find more easily interpretable than a pie chart. Due to the very limited amount of free-to-use icons available, we had to be a little creative on the visual representations."
      ],
      "metadata": {
        "id": "Ri5XcwQY9lS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "order_counts = mammal_data['Orden latinsk navn'].value_counts()\n",
        "total_animals = order_counts.sum()\n",
        "\n",
        "# Waffle chart\n",
        "plt.figure(\n",
        "    FigureClass = Waffle,\n",
        "    rows = 11,\n",
        "    values = order_counts / total_animals * 100,\n",
        "    icons = ['cow', 'dog', 'carrot', 'mouse', 'baseball-bat-ball', 'road-spikes', 'person-digging', 'water', 'horse'],\n",
        "    icon_legend = True,\n",
        "    legend = {\n",
        "        'labels': ['Artiodactyla', 'Carnivora', 'Lagomorpha', 'Rodentia', 'Chiroptera', 'Erinaceomorpha', 'Soricomorpha', 'Cetacea', 'Perissodactyla'],\n",
        "        'loc': 'upper left',\n",
        "        'bbox_to_anchor': (1, 1)})\n",
        "print() #this prevents the chart from being displayed twice"
      ],
      "metadata": {
        "id": "JsU2HyY06eE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perissodactyla has a too small proportion of the data to be displayed here."
      ],
      "metadata": {
        "id": "jJzpUvWj83pN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Geographical data"
      ],
      "metadata": {
        "id": "uSR9kjqU9Jjn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the main reasons for choosing this dataset was because it includes coordinate data for the observations."
      ],
      "metadata": {
        "id": "wzRnvOZC9SEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#copying the relevant columns and adding them to a new df\n",
        "map_columns = {'Latitude': mammal_data['Lat'].copy(),\n",
        "               'Longitude': mammal_data['Long'].copy(),\n",
        "               'Animal': mammal_data['Taxon dansk navn'].copy(),\n",
        "               'Order': mammal_data['Orden latinsk navn'].copy(),\n",
        "               'Inaccuracy (m)': mammal_data['Usikkerhed (m)'].copy(),\n",
        "               'Year': mammal_data[\"Observationsdato\"].copy()}\n",
        "map_df = pd.DataFrame(map_columns)"
      ],
      "metadata": {
        "id": "gBcQwbcd_LeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we want the map to be relatively accurate, we remove all observations where the uncertainty about the location is larger than 1500 meters. We also make sure to round off to less digits in the floats."
      ],
      "metadata": {
        "id": "T_3U2fQgBxRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "map_df = map_df.drop(map_df[map_df['Inaccuracy (m)'] > 1500].index)\n",
        "map_df['Inaccuracy (m)'] = map_df['Inaccuracy (m)'].round(2)"
      ],
      "metadata": {
        "id": "R1DX9hqH_kMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the observations where inaccuracy was not specified, we fill in with \"unknown\" as it looks better than NaN for display on the map."
      ],
      "metadata": {
        "id": "F3WYJi37CPbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "map_df['Inaccuracy (m)'] = map_df['Inaccuracy (m)'].fillna(\"Unknown\")"
      ],
      "metadata": {
        "id": "VCmiVq0qBmqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on geographical data on the coordinate range of the five Danish regions, we want to perform a spatial join to extract what region the observation ocurred and add it as a column in the dataframe. The data regarding Danish regions are from https://www.diva-gis.org/gdata"
      ],
      "metadata": {
        "id": "MAHNzahhAzEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "denmark_regions = gpd.read_file(\"/content/drive/MyDrive/Python/Regioner/DNK_adm1.shp\") #importing coordinates on the regions of Denmark - NB: all the DNK_adm1 files must be in the same folder\n",
        "\n",
        "coordinates_gdf = gpd.GeoDataFrame(map_df, geometry=gpd.points_from_xy(map_df.Longitude, map_df.Latitude)) #extracting the coordinate set from the lat. and long.\n",
        "coordinates_gdf = coordinates_gdf.set_crs(\"EPSG:4326\") #matching the coordinate reference system of the GDFs based on information in the error message\n",
        "\n",
        "spatial_join = gpd.sjoin(coordinates_gdf, denmark_regions, how='left', predicate='within') #matching the coordinates of the observations with the regions with spatial join\n",
        "\n",
        "map_df['Region'] = spatial_join['NAME_1'] #adding the name of the region as a column in the df"
      ],
      "metadata": {
        "id": "7Agc_xsWA96b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We wish to investigate the reason for missing values in the region data, as all observations include coordinates. Therefore we create a subset only including rows with missing region value and display it."
      ],
      "metadata": {
        "id": "owtoG_9OqvdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "map_region_nan = map_df[map_df[\"Region\"].isna()]\n",
        "map_region_nan[\"Animal\"].value_counts()"
      ],
      "metadata": {
        "id": "OY-QEN64FcKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can see that the majority of the missing values relates to mammals living in the sea like seals and whales, where otters and mink are known swimmers as well, which explains why they do not belong to a region. There are also a few bats that might have been flying over the sea. Though, there are also more unexpected values like deer, hares, foxes, and squirrels, which calls for a closer look at the accuracy of the region separation. As we deal with data entered by people, who can make errors, and we have accepted an inaccuracy of 1500 meters or less, it might relate to animals that was observed very close to the shore. We assume this for now and fill in the missing values with \"In and by the ocean\"."
      ],
      "metadata": {
        "id": "MenXl9eVFoBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "map_df[\"Region\"].fillna(\"I eller ved havet\", inplace = True)\n",
        "map_df[\"Region\"].isnull().values.any() #checks for any missing values in the column"
      ],
      "metadata": {
        "id": "piYQ-a1gFf1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now an overview of the amount of animal observations for each region."
      ],
      "metadata": {
        "id": "csuI3xx2wZ0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "map_df[\"Region\"].value_counts()"
      ],
      "metadata": {
        "id": "GWQCt4BmFjgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To investigate the locations of the observations, we create a map displaying pins for only the newly created region \"I eller ved havet\"."
      ],
      "metadata": {
        "id": "P4wgdiLax4XI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sea_and_shore_df = map_df.loc[map_df['Region'] == \"I eller ved havet\"] #creating a df including only animals by the ocean\n",
        "sea_and_shore_map = fm.Map(location=[56.2639, 9.5018], zoom_start=7) #creating a map of Denmark\n",
        "\n",
        "#looping through the relevant information for each row in the df\n",
        "for lat, lon, animal, order, region, inaccuracy, year in zip(sea_and_shore_df['Latitude'],\n",
        "                                                             sea_and_shore_df['Longitude'],\n",
        "                                                             sea_and_shore_df['Animal'],\n",
        "                                                             sea_and_shore_df['Order'],\n",
        "                                                             sea_and_shore_df['Region'],\n",
        "                                                             sea_and_shore_df['Inaccuracy (m)'],\n",
        "                                                             sea_and_shore_df[\"Year\"]):\n",
        "    popup_text = f\"Animal: {animal}<br>Order: {order}<br>Region: {region}<br>Inaccuracy: {inaccuracy} meters<br>Year: {year}\" #choosing the info for the pop up\n",
        "    fm.Marker([lat, lon], popup=fm.Popup(popup_text, max_width=300)).add_to(sea_and_shore_map) #adding the pins to the map\n",
        "\n",
        "display(sea_and_shore_map) #displaying the map with the pins"
      ],
      "metadata": {
        "id": "y07TedAgF76t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This visualization shows us that most of the animals are indeed observed in the ocean or in the fjords. Though, some of the pins seem to be placed on land very close to the shore rather than in water. Very few of the pins in the southernmost Jutland are not placed near the ocean, and they are most likely included because the region coordinate data considers them to be placed in Germany. This shows us that the unexpected observations of land animals outside of the five regions is likely related to the GIS data containing the regions being a bit inaccurate. This was important to explore to know how much we can trust the accuracy of our maps."
      ],
      "metadata": {
        "id": "eKH48FjXyjp1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Addressing the research question"
      ],
      "metadata": {
        "id": "oRm5ULCkgtHR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As our research question is primarily interested in"
      ],
      "metadata": {
        "id": "nuYbfwxLl3IK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_hunter_and_prey = map_df.drop(map_df[map_df['Region'] == \"I eller ved havet\"].index)\n",
        "df_hunter_and_prey"
      ],
      "metadata": {
        "id": "YiK41Dkgh-fX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(df_hunter_and_prey.loc[df_hunter_and_prey['Order'] == 'Carnivora', 'Animal'].unique())\n",
        "\n",
        "predators_todrop = ['Grævling','Tamkat','Spættet sæl','Hvalros','Gråsæl','Ægte sæler','Odder','Katte']\n",
        "\n",
        "# Filtering the DataFrame based on the condition\n",
        "filtered_carnivora = df_hunter_and_prey[df_hunter_and_prey['Order'] == 'Carnivora']\n",
        "\n",
        "# Dropping rows with specific values in the 'Animal' column\n",
        "filtered_carnivora = filtered_carnivora[~filtered_carnivora['Animal'].isin(predators_todrop)]\n",
        "\n",
        "# Now, if you want to see the unique values after dropping, you can use unique()\n",
        "unique_values_after_drop = filtered_carnivora['Animal'].unique()\n",
        "\n",
        "# If you want to modify the original DataFrame, you can use loc to update the values\n",
        "df_hunter_and_prey.loc[df_hunter_and_prey['Order'] == 'Carnivora', 'Animal'] = filtered_df['Animal']\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eLDu9W-hZ4Ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tanker og noter\n",
        "- Vise sammenhæng mellem ræv og rævemad (gnavere og støttetandede)\n",
        "- Lave et nyt kort med kun ræve og byttedyr for se, om der er sammenhæng i lokationen. Forskellige farver på pins.\n",
        "- Måske skal vi tage udgangspunkt i procent af antal observationer frem for antal\n",
        "- Hvordan kan vi bruge desktiptiv statistik?\n",
        "- Haakon siger, at vi skal være opmærksomme på hvilken slags graf vi bruger til hvilke formål\n",
        "- [StackOverflow: Plotting three dimensions of categorical data in Python\n",
        "](https://stackoverflow.com/questions/58303175/plotting-three-dimensions-of-categorical-data-in-python) - En nice visualisering vi kunne bruge med region, år og orden\n",
        "- Hvad med Cramers V?\n",
        "- Det er måske lidt for voldsomt med et kort med alle datapunkterne, da Folium er ret tungt, og det ikke rigtig tjener et formål\n",
        "- Måske et subset til at tjekke dyrene i og ved havet\n",
        "- Evt. bar charts med andel af byttedyr og ræve for hver region (5*2 søjler)\n",
        "- Alternativt sådan en stablet søjle til evt. at vise bytte, ræv og \"andet\""
      ],
      "metadata": {
        "id": "Mofx_GKLx8zX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Byttedyr:\n",
        "- Lagomorpha\n",
        "- Rodentia\n",
        "- Soricomorpha\n",
        "- Erinaceomorpha\n",
        "\n",
        "Rovdyr:\n",
        "- Alle, der ikke lever i havet + grævling, odder, tamkat"
      ],
      "metadata": {
        "id": "nEBd7ltkdo1V"
      }
    }
  ]
}